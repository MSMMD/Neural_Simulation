\documentclass[12pt]{article}
\usepackage{amsmath, amsthm, amssymb}
\usepackage{natbib}
\usepackage[dvipsnames]{xcolor}

\usepackage{url}
\usepackage[colorlinks=true, urlcolor=Cerulean, linkcolor=cyan, citecolor=OliveGreen]{hyperref}

\usepackage[brazil]{babel}

\usepackage[
    a4paper,
    left=2cm,
    right=2cm,
    top=1cm,
    bottom=2cm
]{geometry}

\usepackage{dsfont}
\usepackage{graphicx}

\title{Relatório - Iniciação científica}
\author{Mateus Scheffer Mendes Maziviero Dolce\\Orientadora: Profa. Dra. Aline Duarte de Oliveira}
\date{\today}

\begin{document}
    \maketitle

    \section{Introdução}
    \paragraph{}O cérebro é uma rede complexa com grande número de componentes, os \emph{neurônios}. Ao olhar para
    evidências empíricas, estas sugerem ambos que o cérebro pode ser representado por meio de distribuições de probabilidade
    e que ele processa informação através de inferências probabilísticas. Justifica-se, assim, uma abordagem probabilística na
    modelagem de redes neurais. Realizaremos esta abordagem através do modelo proposto por \citealt{Galves2013}.

    \paragraph{}A dinâmica de cada neurônio depende da atividade passada de seus neurônios pré-sinápticos, o que torna as
    cadeias interagentes, considerando apenas os disparos ocorridos após o seu último disparo. Em outras palavras, cada
    neurônio reinicia sua memória a cada disparo. Essa característica, biologicamente motivada, implica que o sistema possui
    memória de comprimento variável de acordo com o histórico de disparos.

    
    \section{Modelo}
    \label{Modelo}

    \subsection{Definição geral}

    \paragraph{}Seja $I=\{1, 2, \dots, N\}$, com $N \in \mathbb{N}$, um conjunto finito de neurônios. Cada neurônio $i \in I$
    é descrito por uma sequência de disparos ao longo do tempo. Seja $(X_t)_{t \in \mathbb{N}}$ uma cadeia estocástica, assumindo
    valores em $\{0,1\}^t$, definida em um espaço de probabilidade adequado $(\omega, \mathcal{A}, \mathds{P})$, onde

    \begin{equation*}
        X_t(i) =
        \begin{cases}
            1 \text{ se i disparou no tempo t}\\
            0 \text{ se i }\textbf{não}\text{ disparou no tempo t}.
        \end{cases}
    \end{equation*}

    Para cada $t \in \mathbb{N}$, seja $\mathcal{F}_t$ a $\sigma$-álgebra gerada por todos os neurônios do sistema e todos
    os eventos passados até o tempo $t$, ou seja, $\mathcal{F}_t := \sigma(X_s(i) : s \leq t, i \in I)$, e defina o tempo
    do último disparo do neurônio $i$ antes de $t$, dado por

    \begin{equation*}
        L^i_t = sup\{s \leq t : X_s(i) = 1\},
    \end{equation*}

    Com a convenção $L^i_t = -1$ quando $sup(\emptyset)$.

    \paragraph{}Considerando a cadeia $(X_t)_{t \in \mathbb{N}}$, $X_t(i)$ e $X_t(j)$ são independentes
    $\forall(i, j) \in I^2: i \neq j$ e $t \in \mathbb{N}$.

    \paragraph{}Considere $V_t(i)$ uma variável aleatória que descreve o potencial do neurônioq $i$ no tempo $t$ e
    seja $\varphi$ uma função não decrescente que associa $V_t(i)$ à probabilidade de ocorrência de um disparo de
    $i$ no tempo $t+1$. Como $\varphi$ representa uma função de probabilidade de disparo,
    $\varphi: \mathbb{R} \rightarrow [0,1]$ e $X_{t+1}(i) \sim \beta\big(\varphi(V_t(i))\big)$.

    \paragraph{}Basta agora definir $V_s(i)$ em termos de $(X_t)_{t\leq s}$. Sendo $W_{j\rightarrow i}$ o peso que representa
    a influência do disparo de $j$ em $i$, com $(j, i) \in I^2: j \neq i$, e $g$ uma função de vazamento como descrito por
    \citealt{Galves2013}, definimos

    \begin{equation}
        V_t(i) = 
        \begin{cases}
            \sum_{j \in I\setminus \{i\}} \sum_{s = L^i_{t+1}}^{t} g(t-s) \cdot W_{j\rightarrow i} \cdot X_s(j) \text{, se } t > L^i_t\\
            0 \text{, se } t = L^i_t
        \end{cases}
        \label{DefV}
    \end{equation}

    \subsection{Propriedades markovianas}
    \paragraph{}Suponha que $i$ não tenha disparado no tempo $t$, então, por \eqref{DefV},
    \begin{equation*}
        \begin{aligned}
            V_t(i) &= \sum_{j \in I\setminus \{i\}} \sum_{s = L^i_{t+1}}^{t} g(t-s) \cdot W_{j\rightarrow i} \cdot X_s(j)\\
                   &= \sum_{j \in I\setminus \{i\}} \sum_{s = L^i_{t+1}}^{t-1} g(t-s) \cdot W_{j\rightarrow i} \cdot X_s(j) +
                      \sum_{j \in I\setminus \{i\}} g(0) \cdot W_{j\rightarrow i} \cdot X_s(j),
        \end{aligned}
    \end{equation*}
    suponha também que $g$ é tal que a propriedade $g(t) = g(t-s)g(s)$ é válida $\forall (t, s) \in \mathbb{N}^2: s<t$,

    \begin{equation*}
        \begin{aligned}
            \Rightarrow
            V_t(i) &= g(1) \sum_{j \in I\setminus \{i\}} \sum_{s = L^i_{t+1}}^{t-1} g(t-1-s) \cdot W_{j\rightarrow i} \cdot X_s(j) +
            \sum_{j \in I\setminus \{i\}} g(0) \cdot W_{j\rightarrow i} \cdot X_s(j)\\
            &= g(1) V_{t-1}(i) + \sum_{j \in I\setminus \{i\}} g(0) \cdot W_{j\rightarrow i} \cdot X_s(j).
        \end{aligned}
    \end{equation*}

    \paragraph{}Para que $g$ possua a propriedade necessária, deverá seguir uma função exponencial de Cauchy, analisada em
    \citealt{Sahoo2011}. Então, $g$ é na forma $\rho^x$. Como $g$ é uma função de vazamento, $g: \mathbb{R} \rightarrow [0, 1]$, logo
    $\rho \in [0,1]$. Por fim, teremos

    \begin{equation}
        V_t(i) = \rho V_{t-1}(i) + \sum_{j \in I\setminus \{i\}} W_{j\rightarrow i} \cdot X_s(j).
        \label{SimpV}
    \end{equation}

    \subsection{Definição da Phi}
        \paragraph{}Fixado $N$ e $\rho$, resta encontrar uma função $\varphi$ adequada. Como queremos que $\varphi$ seja não decrescente e
        com contradomínio $[0,1]$, uma sigmoide se apresenta como um ótimo candidato. Então, teremos

        \begin{equation}
            \varphi(x) = \frac{1}{1+e^{-f(x)}}.
            \label{PhiGeral}
        \end{equation}

        Buscando simplificar a função $\varphi$ tendo certo controle de seu aspecto, optamos por $f$ ser um polinômio de grau $1$.
        Desta forma, $f(x) = \frac{x}{a} - b$, com $a$ controlando a inclinação da sigmoide e $b$, o deslocamento horizontal.

        \paragraph{}Seja $\epsilon$ a probabilidade de disparo espontâneo, isto é, com potencial do neurônio em questão zerado.
        \begin{equation*}
            \epsilon = \varphi(0) = \frac{1}{1+ e^{-(0/a -b)}} = \frac{1}{1+ e^{0+b}} = \frac{1}{1+ e^{b}}
        \end{equation*}
        \begin{equation}
            \Rightarrow b = ln\big(\frac{1}{\epsilon} - 1\big).
            \label{DefB}
        \end{equation}

        \paragraph{}Seja $p_{w^+}$ e $p_{w^-}$ a variação de potencial positiva e negativa, respectivamente, esperada em um
        neurônio $j$ de cada $i \in I: i \neq j$, caso $i$ dispare. Desta forma, a variação de potencial esperada em $j$ é
        \begin{equation*}
            (p_{w^+} - p_{w^-})(N-1),
        \end{equation*}
        no caso extremal onde todos os demais neurônios disparem. Então, com o intuito de compensar esta variação,
        tomaremos um $a = (p_{w^+} - p_{w^-})(N-1)/k$ inicial, com $k$ sendo uma constante a ser definida.
        
    
    \section{Simulação}

        \paragraph{}Para simular o modelo estocástico a tempo discreto descrito em \ref{Modelo}, um algoritmo foi desenvolvido para gerar
        a sequência de $n$ disparos em uma rede de $N$ neurônios em linguagem \emph{C++17}. A decisão se um neurônio dispara ou não é
        feita a partir de um $U_t(i) \in [0, 1]$ obtido de maneira pseudo-aleatória com \emph{Mersenne Twister 19937}, \citealt{Matsumoto1998}.
        O neurônio $i$ dispara no tempo $t$ se, e somente se, $U_t(i) < \varphi\big(V_t(i)\big)$, garantindo

        \begin{equation}
            \mathds{P}(X_{t+1}(i) = 1 | \mathcal{F}_t) = \varphi\big(V_t(i)\big)
            \label{ProbPhiV}
        \end{equation}

        \paragraph{}Na ausência de um grafo de neurônios específico para a simulação, utiliza-se um grafo direcionado do tipo Erdös-Rényi
        com pesos nas arestas, \citealt{ErdosRenye1960}. Para cada par $(i, j) \in I^2: i \neq j$,
        \begin{gather}
            \mathds{P}(W_{i\rightarrow j} = 1) = p_{w^+} \label{Defpmax}\\
            \mathds{P}(W_{i\rightarrow j} = -1) = p_{w^-} \label{Defpmin}\\
            \mathds{P}(i \text{ não influencia em } j) = 1 - (p_{w^+} + p_{w^-})
        \end{gather}

    \section{Tunning da Phi}

        \paragraph{}Baseando-se no simulador disponibilizado em \citealt{Galves2024},
        fixaremos $p_{w^+} = 0.2$ e $p_{w^-} = 0.05$.
    % TO-DO list
    
    % - Tunnig da Phi
        % Simular com mudanças no p0 e k para justificar (p0/pi)
        % Simular com varios parâmetros para mostrar adptabilidade da phi

    % - Validação do modelo
        % phi <- phi - p0    (então phi(0)=0)
        % pmax = 1, pmin = 0 

    \newpage
    \bibliography{references}
    \bibliographystyle{plainnat}
\end{document}